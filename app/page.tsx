'use client'

import { useCallback, useEffect } from 'react'
import AudioPlayer from './components/AudioPlayer'
import ResponseDisplay from './components/ResponseDisplay'
import StatusText from './components/StatusText'
import VoiceButton from './components/VoiceButton'
import ErrorDisplay from './components/ErrorDisplay'
import PulseIndicator from './components/PulseIndicator'
import ChatContainer from './components/ChatContainer'
import { useVoiceRecorder } from './hooks/useVoiceRecorder'
import { useAppState } from './hooks/useAppState'
import { useAudioAPI } from './hooks/useAudioAPI'

export default function Home() {
  const {
    appState,
    displayText,
    responseText,
    conversationHistory,
    audioBlob,
    isAudioPlaying,
    setAppState,
    setDisplayText,
    setResponseText,
    setConversationHistory,
    setAudioBlob,
    setIsAudioPlaying,
    getStatusText,
  } = useAppState()

  const { transcript, volumeLevel, error, isFinalTranscript, startRecording, stopRecording, resetRecorder } = useVoiceRecorder()
  const { handleChatAPI } = useAudioAPI()

  // transcript ì—…ë°ì´íŠ¸ë  ë•Œ displayTextë„ ì—…ë°ì´íŠ¸
  useEffect(() => {
    if (appState === 'listening' && transcript) {
      setDisplayText(transcript)
    }
  }, [transcript, appState, setDisplayText])

  // ìµœì¢… ê²°ê³¼ê°€ ë‚˜ì™”ì„ ë•Œ ìë™ìœ¼ë¡œ ì²˜ë¦¬ ì‹œì‘
  useEffect(() => {
    if (isFinalTranscript && appState === 'listening' && transcript) {
      console.log('âœ… ìµœì¢… ìŒì„± ì¸ì‹ ì™„ë£Œ:', transcript)
      setTimeout(async () => {
        await stopRecording()
        setAppState('processing')
      }, 500)
    }
  }, [isFinalTranscript, appState, transcript, stopRecording, setAppState])

  const handleButtonClick = useCallback(async () => {
    if (appState === 'idle') {
      console.log('ğŸ¯ ìƒíƒœ ë³€ê²½: idle â†’ listening')
      setAppState('listening')
      resetRecorder()
      setDisplayText('')

      try {
        await startRecording()
        console.log('ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘')
      } catch (err) {
        console.error('âŒ Recording error:', err)
        setAppState('idle')
      }
    } else if (appState === 'listening') {
      console.log('ğŸ¯ ìƒíƒœ ë³€ê²½: listening â†’ processing (ìˆ˜ë™ ì¤‘ì§€)')
      await stopRecording()
      console.log('â¹ï¸ ìŒì„± ì¸ì‹ ì¤‘ì§€')
    }
  }, [appState, startRecording, stopRecording, resetRecorder, setAppState, setDisplayText])

  const handleProcessing = useCallback(async () => {
    if (!transcript) {
      console.log('âš ï¸ transcript ì—†ìŒ, idle ìƒíƒœë¡œ ë³µê·€')
      setAppState('idle')
      return
    }

    console.log('ğŸ“¤ ì‚¬ìš©ì ë©”ì‹œì§€ ì „ì†¡:', transcript)

    try {
      // Chat API í˜¸ì¶œ
      console.log('ğŸ”— Chat API í˜¸ì¶œ ì¤‘...')
      const aiResponse = await handleChatAPI(transcript, conversationHistory, setConversationHistory)
      setResponseText(aiResponse)
      console.log('âœ… AI ì‘ë‹µ ìˆ˜ì‹ :', aiResponse)
      console.log('ğŸ’¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ, ì´ ë©”ì‹œì§€ ìˆ˜:', conversationHistory.length + 2)

      // TTS API í˜¸ì¶œ (ì„ì‹œ ì£¼ì„ ì²˜ë¦¬)
      // console.log('ğŸ”— TTS API í˜¸ì¶œ ì¤‘...')
      // const audioBlob = await handleTTSAPI(aiResponse)
      // console.log('âœ… ìŒì„± íŒŒì¼ ìˆ˜ì‹ , í¬ê¸°:', audioBlob.size, 'bytes')
      // setAudioBlob(audioBlob)
      // console.log('ğŸ”Š ìŒì„± ìƒì„± ì™„ë£Œ, ì¬ìƒ ì¤€ë¹„')

      // ì‘ë‹µ ìƒíƒœë¡œ ì „í™˜
      console.log('ğŸ¯ ìƒíƒœ ë³€ê²½: processing â†’ speaking')
      setAppState('speaking')
      // setIsAudioPlaying(true)
      // console.log('â–¶ï¸ ìŒì„± ì¬ìƒ ì‹œì‘')
    } catch (err) {
      console.error('âŒ Processing error:', err)
      setAppState('idle')
    }
  }, [transcript, setAppState, handleChatAPI, conversationHistory, setConversationHistory, setResponseText])

  // processing ìƒíƒœì¼ ë•Œ API í˜¸ì¶œ
  useEffect(() => {
    if (appState === 'processing' && transcript) {
      handleProcessing()
    }
  }, [appState, transcript, handleProcessing])

  const handleAudioPlayEnd = useCallback(() => {
    console.log('â¹ï¸ ìŒì„± ì¬ìƒ ì™„ë£Œ')
    setIsAudioPlaying(false)

    // 2ì´ˆ ëŒ€ê¸° í›„ ìë™ ë³µê·€
    console.log('â³ 2ì´ˆ ëŒ€ê¸° ì¤‘...')
    setTimeout(() => {
      console.log('ğŸ¯ ìƒíƒœ ë³€ê²½: speaking â†’ idle')
      setAppState('idle')
      setResponseText('')
      setDisplayText('')
      setAudioBlob(null)
      console.log('âœ… ì´ˆê¸° ìƒíƒœë¡œ ë³µê·€ ì™„ë£Œ')
    }, 2000)
  }, [setIsAudioPlaying, setAppState, setResponseText, setDisplayText, setAudioBlob])

  return (
    <div className="w-full h-screen bg-white flex flex-col items-center justify-center p-4 overflow-hidden">
      {/* ìƒë‹¨ ìƒíƒœ í…ìŠ¤íŠ¸ ë˜ëŠ” ë°›ì•„ì“°ê¸° í…ìŠ¤íŠ¸ */}
      {appState !== 'idle' && appState !== 'listening' && (
        <div
          className="flex items-end justify-center overflow-y-auto max-h-[40vh] pb-4"
          style={{
            marginBottom: '24px',
          }}
        >
          {appState === 'processing' && (
            <StatusText text={getStatusText(appState, displayText, responseText)} isActive={true} />
          )}
          {appState === 'speaking' && responseText && (
            <ResponseDisplay text={responseText} isVisible={true} />
          )}
        </div>
      )}

      {/* ì¤‘ì•™ ì˜ì—­ */}
      {(appState === 'idle' || appState === 'listening') ? (
        // idle/listening: ì›ì´ ì¤‘ì•™ì—
        <div className="flex-1 flex flex-col items-center justify-center relative w-full">
          {appState === 'idle' && (
            <div className="mb-12">
              <p className="text-base sm:text-base md:text-xl font-black text-gray-600">{getStatusText(appState, displayText, responseText)}</p>
            </div>
          )}
          <div className="relative z-10">
            <VoiceButton
              isAnimating={appState === 'listening'}
              scale={appState === 'listening' ? 0.8 + (volumeLevel / 100) * 0.5 : 1}
              isListening={appState === 'listening'}
              onClick={handleButtonClick}
            />
          </div>
        </div>
      ) : (
        // processing/speaking: ì±„íŒ… ì»¨í…Œì´ë„ˆ
        <div className="flex-1 flex items-center justify-center relative w-full">
          <ChatContainer
            messages={conversationHistory}
            isVisible={appState === 'speaking'}
            isTyping={appState === 'speaking'}
          />
        </div>
      )}

      {/* ì› - processing/speaking ìƒíƒœì—ì„œ ë°”í…€ì— í‘œì‹œ */}
      {(appState === 'processing' || appState === 'speaking') && (
        <div
          className="absolute left-1/2 transform -translate-x-1/2 z-10 transition-all duration-500"
          style={{
            bottom: appState === 'speaking' ? '20px' : '80px',
          }}
        >
          <VoiceButton
            isAnimating={false}
            scale={0.25}
            isListening={false}
            onClick={handleButtonClick}
          />
        </div>
      )}

      {/* ìŒì„± ì¬ìƒ ì»´í¬ë„ŒíŠ¸ */}
      <AudioPlayer
        audioBlob={audioBlob}
        isPlaying={isAudioPlaying}
        onPlayEnd={handleAudioPlayEnd}
      />

      {/* ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ */}
      <ErrorDisplay error={error} />

      {/* ë§¤ìš° í•˜ë‹¨ ìƒíƒœ ì¸ë””ì¼€ì´í„° */}
      <PulseIndicator isVisible={appState === 'listening'} />
    </div>
  )
}
