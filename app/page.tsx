'use client'

import { useCallback, useEffect, useRef, useState } from 'react'
import AudioPlayer from './components/AudioPlayer'
import ResponseDisplay from './components/ResponseDisplay'
import StatusText from './components/StatusText'
import VoiceButton from './components/VoiceButton'
import { useVoiceRecorder } from './hooks/useVoiceRecorder'

type AppState = 'idle' | 'listening' | 'processing' | 'speaking'

export default function Home() {
  const [appState, setAppState] = useState<AppState>('idle')
  const [responseText, setResponseText] = useState('')
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null)
  const [isAudioPlaying, setIsAudioPlaying] = useState(false)
  const [conversationHistory, setConversationHistory] = useState<Array<{ role: 'user' | 'assistant'; content: string }>>([])
  const [displayText, setDisplayText] = useState('')

  const { transcript, volumeLevel, error, startRecording, stopRecording, resetRecorder } = useVoiceRecorder()

  const recordingTimeoutRef = useRef<NodeJS.Timeout | null>(null)

  // transcript ì—…ë°ì´íŠ¸ë  ë•Œ displayTextë„ ì—…ë°ì´íŠ¸
  useEffect(() => {
    if (appState === 'listening' && transcript) {
      setDisplayText(transcript)
      console.log('ğŸ“ ìŒì„± ì¸ì‹:', transcript)
    }
  }, [transcript, appState])

  const getStatusText = () => {
    switch (appState) {
      case 'idle':
        return 'íƒ­í•˜ì—¬ ì‹œì‘'
      case 'listening':
        return 'ë“£ëŠ” ì¤‘...'
      case 'processing':
        return 'ìƒê°í•˜ëŠ” ì¤‘...'
      case 'speaking':
        return responseText
      default:
        return 'íƒ­í•˜ì—¬ ì‹œì‘'
    }
  }

  const handleChatAPI = useCallback(
    async (userMessage: string) => {
      try {
        const response = await fetch('/api/chat', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            message: userMessage,
            conversationHistory,
          }),
        })

        if (!response.ok) throw new Error('Chat API ì‹¤íŒ¨')

        const data = await response.json()
        const assistantMessage = data.response

        // ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        const newHistory = [
          ...conversationHistory,
          { role: 'user' as const, content: userMessage },
          { role: 'assistant' as const, content: assistantMessage },
        ]
        setConversationHistory(newHistory)

        return assistantMessage
      } catch (err) {
        console.error('Chat error:', err)
        throw err
      }
    },
    [conversationHistory]
  )

  const handleTTSAPI = useCallback(async (text: string) => {
    try {
      const response = await fetch('/api/tts', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text }),
      })

      if (!response.ok) throw new Error('TTS API ì‹¤íŒ¨')

      const audioData = await response.blob()
      return audioData
    } catch (err) {
      console.error('TTS error:', err)
      throw err
    }
  }, [])

  const handleButtonClick = useCallback(async () => {
    if (appState === 'idle') {
      // ìŒì„± ì¸ì‹ ì‹œì‘
      setAppState('listening')
      resetRecorder()
      setDisplayText('')

      try {
        await startRecording()
        // ì¹¨ë¬µ ê°ì§€ë¡œ ìë™ ì¤‘ì§€ë¨ - íƒ€ì´ë¨¸ ì œê±°
      } catch (err) {
        console.error('Recording error:', err)
        setAppState('idle')
      }
    } else if (appState === 'listening') {
      // ë…¹ìŒ ì¤‘ì§€ (ìˆ˜ë™ ì¤‘ì§€)
      if (recordingTimeoutRef.current) clearTimeout(recordingTimeoutRef.current)
      await stopRecording()
      handleProcessing()
    }
  }, [appState, startRecording, stopRecording, resetRecorder])

  // ìŒì„± ì¸ì‹ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì²˜ë¦¬ ì‹œì‘
  useEffect(() => {
    if (appState === 'listening' && transcript) {
      const timer = setTimeout(() => {
        handleProcessing()
      }, 500)
      return () => clearTimeout(timer)
    }
  }, [transcript, appState])

  const handleProcessing = useCallback(async () => {
    if (!transcript) {
      setAppState('idle')
      return
    }

    setAppState('processing')

    try {
      // Chat API í˜¸ì¶œ
      const aiResponse = await handleChatAPI(transcript)
      setResponseText(aiResponse)

      // TTS API í˜¸ì¶œ
      const audio = await handleTTSAPI(aiResponse)
      setAudioBlob(audio)

      // ìŒì„± ì¬ìƒ ì‹œì‘
      setAppState('speaking')
      setIsAudioPlaying(true)
    } catch (err) {
      console.error('Processing error:', err)
      setAppState('idle')
    }
  }, [transcript, handleChatAPI, handleTTSAPI])

  const handleAudioPlayEnd = useCallback(() => {
    setIsAudioPlaying(false)
    setAppState('idle')
    setResponseText('')
    setDisplayText('')
    setAudioBlob(null)
  }, [])

  return (
    <div className="w-full h-screen bg-white flex flex-col items-center justify-center p-4 overflow-hidden">
      {/* ìƒë‹¨ ìƒíƒœ í…ìŠ¤íŠ¸ */}
      <div className="flex-1 flex items-end justify-center mb-12">
        <StatusText text={getStatusText()} isActive={appState !== 'idle'} />
      </div>

      {/* ì¤‘ì•™ ë§ˆì´í¬ ë²„íŠ¼ */}
      <div
        className="flex-1 flex items-center justify-center transition-all duration-500"
        style={{
          transform: appState === 'speaking' ? 'translateY(80px)' : 'translateY(0)',
        }}
      >
        <div className="relative">
          <VoiceButton
            isAnimating={appState === 'listening'}
            scale={appState === 'listening' ? 0.85 + (volumeLevel / 100) * 0.3 : 1}
            isListening={appState === 'listening'}
            onClick={handleButtonClick}
          />
        </div>
      </div>

      {/* í•˜ë‹¨ í…ìŠ¤íŠ¸ í‘œì‹œ ì˜ì—­ */}
      <div className="flex-1 flex items-start justify-center pt-4 px-4">
        {appState === 'listening' && displayText && (
          <ResponseDisplay text={displayText} isVisible={true} />
        )}
        {appState === 'processing' && displayText && (
          <ResponseDisplay text={displayText} isVisible={true} />
        )}
        {appState === 'speaking' && responseText && (
          <ResponseDisplay text={responseText} isVisible={true} />
        )}
      </div>

      {/* ìŒì„± ì¬ìƒ ì»´í¬ë„ŒíŠ¸ */}
      <AudioPlayer
        audioBlob={audioBlob}
        isPlaying={isAudioPlaying}
        onPlayStart={() => {}}
        onPlayEnd={handleAudioPlayEnd}
        onVolumeChange={() => {}}
      />

      {/* ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ */}
      {error && (
        <div className="fixed top-4 left-4 right-4 bg-red-100 border border-red-400 text-red-700 px-4 py-2 rounded">
          {error}
        </div>
      )}

      {/* ë§¤ìš° í•˜ë‹¨ ìƒíƒœ ì¸ë””ì¼€ì´í„° */}
      {appState === 'listening' && (
        <div className="pb-6">
          <div className="flex gap-1 justify-center">
            <div className="w-1 h-1 rounded-full bg-gray-400 animate-pulse" />
            <div className="w-1 h-1 rounded-full bg-gray-400 animate-pulse" style={{ animationDelay: '0.1s' }} />
            <div className="w-1 h-1 rounded-full bg-gray-400 animate-pulse" style={{ animationDelay: '0.2s' }} />
          </div>
        </div>
      )}
    </div>
  )
}
