'use client'

import { useCallback, useRef, useEffect } from 'react'
import { ConversationHistory } from '../types'
import { useAudioAPI } from './useAudioAPI'
import { detectLanguage } from '../utils/language-detector'
import { AUDIO_CONFIG } from '@/app/constants/audio'

interface UseChatHandlerProps {
  conversationHistory: ConversationHistory
  onResponseReceived: (response: string) => void
  onStateChange: (state: 'processing' | 'speaking') => void
  onLanguageDetected: (language: string) => void
  onError: () => void
  onAudioGenerated: (audioBlob: Blob) => void
  onPlayStart: () => void
}

/**
 * Chat API í˜¸ì¶œ, ì–¸ì–´ ê°ì§€, TTS ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì»¤ìŠ¤í…€ í›…
 */
export function useChatHandler({
  conversationHistory,
  onResponseReceived,
  onStateChange,
  onLanguageDetected,
  onError,
  onAudioGenerated,
  onPlayStart,
}: UseChatHandlerProps) {
  const { handleChatAPI, handleTTSAPI } = useAudioAPI()
  const conversationHistoryRef = useRef(conversationHistory)

  // conversationHistory ë³€ê²½ë  ë•Œë§ˆë‹¤ ref ì—…ë°ì´íŠ¸
  useEffect(() => {
    conversationHistoryRef.current = conversationHistory
  }, [conversationHistory])


  const handleFinalTranscript = useCallback(
    (finalText: string) => {
      console.log('ğŸ“¤ ë°±ê·¸ë¼ìš´ë“œì—ì„œ Chat API í˜¸ì¶œ:', finalText)
      console.log('ğŸ“‹ í˜„ì¬ conversationHistory:', conversationHistoryRef.current)

      // ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì–¸ì–´ ê°ì§€
      const detectedLanguage = detectLanguage(finalText)
      if (detectedLanguage) {
        console.log(`ğŸŒ ì–¸ì–´ ê°ì§€: ${finalText} â†’ ${detectedLanguage}`)
        onLanguageDetected(detectedLanguage)
      }

      // Promiseë¡œ í˜¸ì¶œ (ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ)
      handleChatAPI(finalText, conversationHistoryRef.current, (newHistory) => {
        // conversationHistory ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (refì— ë¨¼ì € ì €ì¥)
        conversationHistoryRef.current = newHistory
      })
        .then(async (aiResponse) => {
          console.log('âœ… Chat API ì‘ë‹µ (ë°±ê·¸ë¼ìš´ë“œ):', aiResponse)
          onResponseReceived(aiResponse)

          // ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ 1ë²ˆ TTS ì²˜ë¦¬ (API ë¹„ìš© ì ˆê°)
          try {
            console.log('ğŸµ TTS ì²˜ë¦¬ ì‹œì‘ (ì „ì²´ í…ìŠ¤íŠ¸)')

            const audioBlob = await handleTTSAPI(aiResponse)
            console.log('âœ… TTS ì²˜ë¦¬ ì™„ë£Œ')

            // TTS ì™„ë£Œ í›„ ì¬ìƒ ì‹œì‘
            setTimeout(() => {
              console.log('ğŸ¯ ìƒíƒœ ë³€ê²½: processing â†’ speaking')
              onStateChange('speaking')
              onAudioGenerated(audioBlob)
              onPlayStart()
            }, AUDIO_CONFIG.TTS_DELAY)
          } catch (ttsErr) {
            console.error('âŒ TTS ì—ëŸ¬:', ttsErr)
            onError()
          }
        })
        .catch((err) => {
          console.error('âŒ Chat API ì—ëŸ¬ (ë°±ê·¸ë¼ìš´ë“œ):', err)
          onError()
        })
    },
    [handleChatAPI, handleTTSAPI, onResponseReceived, onStateChange, onLanguageDetected, onError, onAudioGenerated, onPlayStart]
  )

  return { handleFinalTranscript }
}
